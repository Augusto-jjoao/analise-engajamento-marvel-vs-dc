{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd4b34e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\UFOP\\5º Semestre\\Análise de Mídias Sociais\\Trabalho Final\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de: dataset_Marvel.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-01 22:39:04,136 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total carregado: 617539 comentários.\n",
      "Iniciando o treino... Pode ir dormir.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 496.95it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Batches: 100%|██████████| 19299/19299 [1:32:00<00:00,  3.50it/s] \n",
      "2026-02-02 00:11:15,536 - BERTopic - Embedding - Completed ✓\n",
      "2026-02-02 00:11:15,537 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2026-02-02 00:56:49,957 - BERTopic - Dimensionality - Completed ✓\n",
      "2026-02-02 00:56:49,972 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2026-02-02 00:58:57,666 - BERTopic - Cluster - Completed ✓\n",
      "2026-02-02 00:58:57,823 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-02-02 00:59:10,129 - BERTopic - Representation - Completed ✓\n",
      "2026-02-02 00:59:25,047 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino finalizado! Salvando o cérebro do modelo...\n",
      "TUDO PRONTO! Modelo salvo em 'modelo_marvel_final' e tabela em 'tabela_topicos_marvel.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# --- 1. CARREGAR DADOS (Parte Rápida) ---\n",
    "ARQUIVO_ALVO = \"dataset_Marvel.json\"\n",
    "print(f\"Carregando dados de: {ARQUIVO_ALVO}...\")\n",
    "\n",
    "with open(ARQUIVO_ALVO, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "todos_comentarios = []\n",
    "for movie_name, movie_data in data.items():\n",
    "    comments_list = movie_data.get(\"comments\", [])\n",
    "    for comment in comments_list:\n",
    "        texto = comment.get(\"text\", \"\")\n",
    "        if len(texto) > 10: \n",
    "            todos_comentarios.append(texto)\n",
    "\n",
    "print(f\"Total carregado: {len(todos_comentarios)} comentários.\")\n",
    "\n",
    "# --- 2. TREINAR E SALVAR (Parte Demorada - A Noite Toda) ---\n",
    "print(\"Iniciando o treino... Pode ir dormir.\")\n",
    "\n",
    "# Configura\n",
    "topic_model = BERTopic(language=\"multilingual\", verbose=True)\n",
    "\n",
    "# Treina (Vai demorar horas)\n",
    "topics, probs = topic_model.fit_transform(todos_comentarios)\n",
    "\n",
    "# --- 3. SALVAMENTO DE SEGURANÇA (O Pulo do Gato) ---\n",
    "print(\"Treino finalizado! Salvando o cérebro do modelo...\")\n",
    "topic_model.save(\"modelo_marvel_final\")\n",
    "\n",
    "# Salva também a tabela em Excel/CSV para garantir\n",
    "info_topicos = topic_model.get_topic_info()\n",
    "nome_saida = \"tabela_topicos_marvel.csv\"\n",
    "info_topicos.to_csv(nome_saida, index=False)\n",
    "\n",
    "print(f\"TUDO PRONTO! Modelo salvo em 'modelo_marvel_final' e tabela em '{nome_saida}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f9a28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Documents\\UFOP\\5º Semestre\\Análise de Mídias Sociais\\Trabalho Final\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dados de: dataset_DC.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-02 13:12:43,505 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total carregado (DC): 225634 comentários.\n",
      "Iniciando o treino para DC...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "Loading weights: 100%|██████████| 199/199 [00:00<00:00, 593.90it/s, Materializing param=pooler.dense.weight]                               \n",
      "BertModel LOAD REPORT from: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "Batches: 100%|██████████| 7052/7052 [35:45<00:00,  3.29it/s]  \n",
      "2026-02-02 13:48:37,148 - BERTopic - Embedding - Completed ✓\n",
      "2026-02-02 13:48:37,149 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2026-02-02 13:58:14,667 - BERTopic - Dimensionality - Completed ✓\n",
      "2026-02-02 13:58:14,674 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2026-02-02 13:59:02,733 - BERTopic - Cluster - Completed ✓\n",
      "2026-02-02 13:59:02,788 - BERTopic - Representation - Fine-tuning topics using representation models.\n",
      "2026-02-02 13:59:06,612 - BERTopic - Representation - Completed ✓\n",
      "2026-02-02 13:59:11,839 - BERTopic - WARNING: When you use `pickle` to save/load a BERTopic model,please make sure that the environments in which you saveand load the model are **exactly** the same. The version of BERTopic,its dependencies, and python need to remain the same.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino DC finalizado! Salvando modelo...\n",
      "TUDO PRONTO! Modelo salvo em 'modelo_dc_final' e tabela em 'tabela_topicos_dc.csv'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# --- 1. CARREGAR DADOS DA DC ---\n",
    "ARQUIVO_ALVO = \"dataset_DC.json\"\n",
    "print(f\"Carregando dados de: {ARQUIVO_ALVO}...\")\n",
    "\n",
    "with open(ARQUIVO_ALVO, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "todos_comentarios_dc = []\n",
    "for movie_name, movie_data in data.items():\n",
    "    comments_list = movie_data.get(\"comments\", [])\n",
    "    for comment in comments_list:\n",
    "        texto = comment.get(\"text\", \"\")\n",
    "        # Filtro básico: ignora comentários muito curtos\n",
    "        if len(texto) > 10: \n",
    "            todos_comentarios_dc.append(texto)\n",
    "\n",
    "print(f\"Total carregado (DC): {len(todos_comentarios_dc)} comentários.\")\n",
    "\n",
    "# --- 2. TREINAR E SALVAR (Pode demorar algumas horas) ---\n",
    "print(\"Iniciando o treino para DC...\")\n",
    "\n",
    "# Configura\n",
    "topic_model_dc = BERTopic(language=\"multilingual\", verbose=True)\n",
    "\n",
    "# Treina\n",
    "topics_dc, probs_dc = topic_model_dc.fit_transform(todos_comentarios_dc)\n",
    "\n",
    "# --- 3. SALVAMENTO ---\n",
    "print(\"Treino DC finalizado! Salvando modelo...\")\n",
    "topic_model_dc.save(\"modelo_dc_final\")\n",
    "\n",
    "# Salva a tabela\n",
    "info_topicos_dc = topic_model_dc.get_topic_info()\n",
    "nome_saida = \"tabela_topicos_dc.csv\"\n",
    "info_topicos_dc.to_csv(nome_saida, index=False)\n",
    "\n",
    "print(f\"TUDO PRONTO! Modelo salvo em 'modelo_dc_final' e tabela em '{nome_saida}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3e3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
